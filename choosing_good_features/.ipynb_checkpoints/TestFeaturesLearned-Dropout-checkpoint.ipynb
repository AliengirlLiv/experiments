{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment - do data augmentations make us learn the right feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two features - one \"advice\", one \"spurious\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import transforms\n",
    "# import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim=8):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop. It is independent of forward\n",
    "        x, y = batch\n",
    "        pred = self.model(x)\n",
    "        loss = F.mse_loss(pred, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "class SepHeadsNN(NN):\n",
    "    def __init__(self, input_dim, hidden_dim=8):\n",
    "        assert input_dim == 2\n",
    "        self.input_preprocess = nn.Linear(1, 8)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(9, hidden_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        SepHeadsNN\n",
    "    def forward(self, x):\n",
    "        input1 = self.input_preprocess(x[:, :1])\n",
    "        full_input = torch.cat([input1, x[:, 1:]], dim=1)\n",
    "        return self.model(full_input)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop. It is independent of forward\n",
    "        x, y = batch\n",
    "        input1 = self.input_preprocess(x[:, :1])\n",
    "        full_input = torch.cat([input1, x[:, 1:]], dim=1)\n",
    "        pred = self.model(full_input)\n",
    "        loss = F.mse_loss(pred, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def get_x(self, y):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_x_dim(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = torch.randn(1)\n",
    "        x = self.get_x(y)\n",
    "        return x.cuda(), y.cuda()\n",
    "\n",
    "class BothEasy(BaseDataset):\n",
    "    def __init__(self, noise=0):\n",
    "        self.noise = noise \n",
    "        \n",
    "    def get_x(self, y):\n",
    "        x1 = y.clone() + torch.randn(1) * self.noise # advice\n",
    "        x2 = -y.clone() + torch.randn(1) * self.noise # spurious\n",
    "        return torch.cat([x1, x2])\n",
    "    \n",
    "    def get_x_dim(self):\n",
    "        return 2\n",
    "\n",
    "class AdviceSum(BaseDataset):\n",
    "    def __init__(self, noise=0):\n",
    "        self.noise = noise \n",
    "       \n",
    "    def get_x(self, y):\n",
    "        x2 = torch.randn(1) # useful non-advice\n",
    "        x1 = y - x2 + torch.randn(1) * self.noise # advice\n",
    "        x3 = -y.clone() + torch.randn(1) * self.noise # spurious\n",
    "        return torch.cat([x1, x2, x3])\n",
    "    \n",
    "    def get_x_dim(self):\n",
    "        return 3  \n",
    "    \n",
    "    \n",
    "class BothEasyRandomized(BothEasy):\n",
    "    def __init__(self, noise=0, random_rate=.2):\n",
    "        self.noise = noise \n",
    "        self.random_rate = random_rate\n",
    "        \n",
    "    def get_x(self, y):\n",
    "        x1 = y.clone() + torch.randn(1) * self.noise # advice\n",
    "        if np.random.uniform() < self.random_rate:\n",
    "            x2 = torch.randn(1)\n",
    "        else:\n",
    "            x2 = -y.clone() + torch.randn(1) * self.noise # spurious\n",
    "        return torch.cat([x1, x2])\n",
    "    \n",
    "    def get_x_dim(self):\n",
    "        return 2\n",
    "    \n",
    "    \n",
    "class AdviceSumSpuriousRandomized(BaseDataset):\n",
    "    def __init__(self, noise=0, random_rate=.2):\n",
    "        self.noise = noise \n",
    "       \n",
    "    def get_x(self, y):\n",
    "        x2 = torch.randn(1) # useful non-advice\n",
    "        x1 = y - x2 + torch.randn(1) * self.noise # advice\n",
    "        if np.random.uniform() < self.random_rate:\n",
    "            x3 = torch.randn(1)\n",
    "        else:\n",
    "            x3 = -y.clone() + torch.randn(1) * self.noise # spurious\n",
    "        return torch.cat([x1, x2, x3])\n",
    "    \n",
    "    def get_x_dim(self):\n",
    "        return 3   \n",
    "    \n",
    "class AdviceSumFullRandomizedTogether(BaseDataset):\n",
    "    def __init__(self, noise=0, random_rate=.2):\n",
    "        self.noise = noise \n",
    "       \n",
    "    def get_x(self, y):\n",
    "        x2 = torch.randn(1) # useful non-advice\n",
    "        x1 = y - x2 + torch.randn(1) * self.noise # advice\n",
    "        if np.random.uniform() < self.random_rate:\n",
    "            x3 = torch.randn(1)\n",
    "            x2 = torch.randn(1)\n",
    "        else:\n",
    "            x3 = -y.clone() + torch.randn(1) * self.noise # spurious\n",
    "        return torch.cat([x1, x2, x3])\n",
    "    \n",
    "    def get_x_dim(self):\n",
    "        return 3   \n",
    "       \n",
    "        \n",
    "class AdviceSumFullRandomizedSolo(BaseDataset):\n",
    "    def __init__(self, noise=0, random_rate=.2):\n",
    "        self.noise = noise \n",
    "       \n",
    "    def get_x(self, y):\n",
    "        x2 = torch.randn(1) # useful non-advice\n",
    "        if np.random.uniform() < self.random_rate:\n",
    "            x1 = torch.randn(1)\n",
    "        else:\n",
    "            x1 = y - x2 + torch.randn(1) * self.noise # advice\n",
    "        if np.random.uniform() < self.random_rate:\n",
    "            x3 = torch.randn(1)\n",
    "        else:\n",
    "            x3 = -y.clone() + torch.randn(1) * self.noise # spurious\n",
    "        return torch.cat([x1, x2, x3])\n",
    "    \n",
    "    def get_x_dim(self):\n",
    "        return 3   \n",
    "       \n",
    "    \n",
    "   \n",
    "    \n",
    "def run_exp(class_name, exp_name=None, max_epochs=20, noise=0):\n",
    "    if exp_name is None:\n",
    "        exp_name = class_name.__name__\n",
    "    print(\"running experiment\", exp_name)\n",
    "    dataset = class_name(noise=noise)\n",
    "    train, val = random_split(dataset, [800, 200])\n",
    "\n",
    "    model = NN(dataset.get_x_dim())\n",
    "    logger = pl.loggers.TensorBoardLogger(f'logs/{exp_name}')\n",
    "    trainer = pl.Trainer(max_epochs=max_epochs, logger=logger)\n",
    "    temp = trainer.fit(model, DataLoader(train), DataLoader(val))\n",
    "    return model\n",
    "\n",
    "\n",
    "def check_gradients(model, num_trials, x_dim):\n",
    "    x = torch.randn(num_trials, x_dim)\n",
    "    y = torch.randn((20, 1))\n",
    "    x.requires_grad = True\n",
    "    pred = model(x)\n",
    "    err = pred - y\n",
    "    err.sum().backward()\n",
    "    print(np.round(x.grad.cpu().numpy(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default performance\n",
    "\n",
    "Expect: agent will use both features, with and without noise, with both features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running experiment BothEasy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olivia/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/olivia/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: you passed in a val_dataloader but have no validation_step. Skipping val loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/olivia/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/olivia/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/olivia/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/olivia/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/olivia/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/olivia/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 33    \n",
      "-------------------------------------\n",
      "33        Trainable params\n",
      "0         Non-trainable params\n",
      "33        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/home/olivia/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fea489243a4b46817ece4224cb4a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/olivia/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/olivia/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: you passed in a val_dataloader but have no validation_step. Skipping val loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 33    \n",
      "-------------------------------------\n",
      "33        Trainable params\n",
      "0         Non-trainable params\n",
      "33        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running experiment BothEasy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b8eb56868e4b2facc5d7c3966cb4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Both Easy\n",
    "both_easy_n0 = run_exp(BothEasy, noise=0)\n",
    "both_easy_n02 = run_exp(BothEasy, noise=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advice Hard\n",
    "both_easy_n0 = run_exp(AdviceSum, noise=0)\n",
    "both_easy_n02 = run_exp(AdviceSum, noise=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H1A - Simplicity of Features\n",
    "\n",
    "* Results: when features are more complex, they take longer to learn\n",
    "* Results: eventually converge to the same place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 33    \n",
      "-------------------------------------\n",
      "33        Trainable params\n",
      "0         Non-trainable params\n",
      "33        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running experiment SumDataset15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa0cf49ab784eaeb3870b8a0d0a92ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run_exp(SumDataset15, max_epochs=10) # Learns more slowly than constant, perfect convergencee\n",
    "# run_exp(SumDataset) # Learns more slowly than constant, perfect convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name             | Type       | Params\n",
      "------------------------------------------------\n",
      "0 | model            | Sequential | 89    \n",
      "1 | input_preprocess | Linear     | 16    \n",
      "------------------------------------------------\n",
      "105       Trainable params\n",
      "0         Non-trainable params\n",
      "105       Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4f163e7a1044c5b9b1477d18006d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = SumDataset15()\n",
    "train, val = random_split(dataset, [800, 200])\n",
    "model = SepHeadsNN(dataset.get_x_dim())\n",
    "exp_name = 'sep_heads_exp'\n",
    "logger = pl.loggers.TensorBoardLogger(f'logs/{exp_name}')\n",
    "trainer = pl.Trainer(max_epochs=10, logger=logger)\n",
    "temp = trainer.fit(model, DataLoader(train), DataLoader(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H1B - Number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 25    \n",
      "-------------------------------------\n",
      "25        Trainable params\n",
      "0         Non-trainable params\n",
      "25        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running experiment num_distractors_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b130033abc459c9024b0eef2a5ac5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 97    \n",
      "-------------------------------------\n",
      "97        Trainable params\n",
      "0         Non-trainable params\n",
      "97        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running experiment num_distractors_10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a529be1b310433d9c59ee536adb9c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 177   \n",
      "-------------------------------------\n",
      "177       Trainable params\n",
      "0         Non-trainable params\n",
      "177       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running experiment num_distractors_20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2833d51823104486a70d88f1b9ae5555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 417   \n",
      "-------------------------------------\n",
      "417       Trainable params\n",
      "0         Non-trainable params\n",
      "417       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running experiment num_distractors_50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77335d608c1348ff991755ed4a88603c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 817   \n",
      "-------------------------------------\n",
      "817       Trainable params\n",
      "0         Non-trainable params\n",
      "817       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running experiment num_distractors_100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f39c8b12583497ca9e1a2f9f5fe45e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 8.0 K \n",
      "-------------------------------------\n",
      "8.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.0 K     Total params\n",
      "0.032     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running experiment num_distractors_1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1186374990ef4d0cbe1681ec2f2ba3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over num distractors\n",
    "for num_distractors in [1, 10, 20, 50, 100, 1000]:\n",
    "    class_name = make_distractor_dataset(num_distractors)\n",
    "    run_exp(class_name, exp_name=f\"num_distractors_{num_distractors}\", max_epochs=20)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H1C - Presence of easier but worse features\n",
    "\n",
    "- Determine how to save model\n",
    "- Determine how to print weights\n",
    "- Determine how to run model on a new dataset\n",
    "- Figure out which feature(s) are used in DoubleFeature, DoubleFeatureNoise, and SumNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 33    \n",
      "-------------------------------------\n",
      "33        Trainable params\n",
      "0         Non-trainable params\n",
      "33        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running experiment DoubleFeatureDataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cc88994a0b483ebc78349fea5bf597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 33    \n",
      "-------------------------------------\n",
      "33        Trainable params\n",
      "0         Non-trainable params\n",
      "33        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running experiment make_dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eacb83517f6469780c9772cafb9301c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 33    \n",
      "-------------------------------------\n",
      "33        Trainable params\n",
      "0         Non-trainable params\n",
      "33        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running experiment DoubleFeatureNoiseDataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06954251a880409f93d13216b46bdc96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 41    \n",
      "-------------------------------------\n",
      "41        Trainable params\n",
      "0         Non-trainable params\n",
      "41        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running experiment SumDistractorDataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89458d15ef064cf597fdcdf03c4e0ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "two_good_model = run_exp(DoubleFeatureDataset, max_epochs=20)\n",
    "class_name = make_distractor_dataset(2)\n",
    "one_good_one_bad_model = run_exp(class_name, max_epochs=20)\n",
    "one_good_one_noisy_model = run_exp(DoubleFeatureNoiseDataset, max_epochs=20)\n",
    "two_good_hard_one_noisy_model = run_exp(SumDistractorDataset, max_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 33    \n",
      "-------------------------------------\n",
      "33        Trainable params\n",
      "0         Non-trainable params\n",
      "33        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running experiment DoubleFeatureDoubleMistakeDataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ae56123d4b4d8f9a04b6c10bf256b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "double_feature_double_mistake = run_exp(DoubleFeatureDoubleMistakeDataset, max_epochs=50)\n",
    "# double_feature_double_mistake2 = run_exp(DoubleFeatureDoubleMistake2Dataset, max_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT: 2 Good\n",
      "model.0.weight torch.Size([8, 2])\n",
      "[[ 0.77 -0.45]\n",
      " [ 0.39 -0.26]\n",
      " [-0.93 -0.22]\n",
      " [ 0.91 -0.48]\n",
      " [ 0.61  0.47]\n",
      " [ 0.69  0.64]\n",
      " [-0.9   0.79]\n",
      " [ 0.41  0.04]]\n",
      "model.0.bias torch.Size([8])\n",
      "[ 0.05  0.37  0.6   0.07 -0.46 -0.62  0.04 -0.55]\n",
      "model.2.weight torch.Size([1, 8])\n",
      "[[ 0.4   0.02 -0.52  0.57 -0.31  0.14 -0.7  -0.05]]\n",
      "model.2.bias torch.Size([1])\n",
      "[-0.1]\n",
      "============================================================\n",
      "EXPERIMENT: 1 Good 1 Bad\n",
      "model.0.weight torch.Size([8, 2])\n",
      "[[ 0.01  0.19]\n",
      " [-1.13  0.07]\n",
      " [ 0.59 -0.03]\n",
      " [ 0.69  0.12]\n",
      " [-0.64 -0.12]\n",
      " [ 0.62 -0.08]\n",
      " [ 0.23 -0.07]\n",
      " [ 0.4  -0.03]]\n",
      "model.0.bias torch.Size([8])\n",
      "[-0.65  1.13 -0.6   0.93 -0.86 -0.61 -0.23  1.37]\n",
      "model.2.weight torch.Size([1, 8])\n",
      "[[-0.13 -0.5   0.7   0.37 -0.4   0.28 -0.09  0.43]]\n",
      "model.2.bias torch.Size([1])\n",
      "[-0.37]\n",
      "============================================================\n",
      "EXPERIMENT: 1 Good 1 Noisy\n",
      "model.0.weight torch.Size([8, 2])\n",
      "[[-0.41  0.44]\n",
      " [-1.17 -0.84]\n",
      " [ 0.19 -0.12]\n",
      " [-0.27 -0.67]\n",
      " [ 0.54 -0.61]\n",
      " [-0.27  0.08]\n",
      " [ 0.73  0.78]\n",
      " [-0.23  0.46]]\n",
      "model.0.bias torch.Size([8])\n",
      "[-0.36  0.11 -0.39  0.08  0.4   0.64 -0.1   0.81]\n",
      "model.2.weight torch.Size([1, 8])\n",
      "[[-0.12 -0.26 -0.17 -0.33 -0.76 -0.27  0.56  0.27]]\n",
      "model.2.bias torch.Size([1])\n",
      "[0.31]\n",
      "============================================================\n",
      "EXPERIMENT: 2 Good+Hard 1 Noisy\n",
      "model.0.weight torch.Size([8, 3])\n",
      "[[ 0.62  0.26  0.39]\n",
      " [ 0.84  0.35  0.73]\n",
      " [-1.    0.54 -0.56]\n",
      " [-0.38 -0.17 -0.02]\n",
      " [-0.97 -0.4  -0.77]\n",
      " [ 0.27 -0.4  -0.11]\n",
      " [ 0.19 -0.1   0.7 ]\n",
      " [ 0.7  -0.37  0.39]]\n",
      "model.0.bias torch.Size([8])\n",
      "[-0.01  0.    0.51 -0.59  0.   -0.14  0.7  -0.36]\n",
      "model.2.weight torch.Size([1, 8])\n",
      "[[ 0.27  0.47 -0.34 -0.   -0.57  0.    0.52  0.49]]\n",
      "model.2.bias torch.Size([1])\n",
      "[-0.19]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "exp_names = ['2 Good', # both features used; seems piecewise linear. All pieces get used.\n",
    "             '1 Good 1 Bad', # bad feature barely used\n",
    "             '1 Good 1 Noisy', \n",
    "             '2 Good+Hard 1 Noisy']\n",
    "exp_models = [two_good_model, one_good_one_bad_model, one_good_one_noisy_model, two_good_hard_one_noisy_model]\n",
    "for exp_name, model in zip(exp_names, exp_models):\n",
    "    print(\"EXPERIMENT:\", exp_name)\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.shape)\n",
    "        print(np.round(param.detach().cpu().numpy(), 2))\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT: 2 Good\n",
      "[[ 0.434 -0.473]\n",
      " [ 0.36  -0.547]\n",
      " [ 0.678 -0.868]\n",
      " [ 0.624 -0.377]\n",
      " [ 0.618 -0.382]\n",
      " [ 0.624 -0.377]\n",
      " [ 0.36  -0.547]\n",
      " [ 0.618 -0.382]\n",
      " [ 0.942 -0.699]\n",
      " [ 0.624 -0.377]\n",
      " [ 0.624 -0.377]\n",
      " [ 0.544 -0.456]\n",
      " [ 0.434 -0.473]\n",
      " [ 0.544 -0.456]\n",
      " [ 0.695 -0.307]\n",
      " [ 0.395 -0.414]\n",
      " [ 0.618 -0.382]\n",
      " [ 0.624 -0.377]\n",
      " [ 0.624 -0.377]\n",
      " [ 0.395 -0.414]]\n",
      "============================================================\n",
      "EXPERIMENT: 1 Good 1 Bad\n",
      "[[ 1.    -0.002]\n",
      " [ 0.999 -0.003]\n",
      " [ 1.    -0.002]\n",
      " [ 1.    -0.002]\n",
      " [ 1.    -0.002]\n",
      " [ 1.    -0.   ]\n",
      " [ 1.    -0.002]\n",
      " [ 1.    -0.002]\n",
      " [ 1.    -0.002]\n",
      " [ 1.    -0.   ]\n",
      " [ 1.    -0.002]\n",
      " [ 1.    -0.002]\n",
      " [ 1.    -0.002]\n",
      " [ 1.    -0.002]\n",
      " [ 1.    -0.002]\n",
      " [ 0.999 -0.003]\n",
      " [ 1.    -0.002]\n",
      " [ 1.    -0.002]\n",
      " [ 1.    -0.002]\n",
      " [ 1.    -0.002]]\n",
      "============================================================\n",
      "EXPERIMENT: 1 Good 1 Noisy\n",
      "[[ 0.06   0.877]\n",
      " [ 0.006  0.995]\n",
      " [ 0.049  1.13 ]\n",
      " [ 0.006  0.995]\n",
      " [ 0.465  0.483]\n",
      " [ 0.006  0.995]\n",
      " [ 0.416  0.536]\n",
      " [ 0.773  0.704]\n",
      " [ 0.006  0.995]\n",
      " [-0.31   0.782]\n",
      " [-0.002  1.003]\n",
      " [ 0.006  0.995]\n",
      " [-0.002  1.003]\n",
      " [ 0.465  0.483]\n",
      " [ 0.006  0.995]\n",
      " [-0.31   0.782]\n",
      " [ 0.049  1.13 ]\n",
      " [ 0.006  0.995]\n",
      " [ 0.06   0.877]\n",
      " [ 0.06   0.877]]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "exp_names = ['2 Good', # both features used; seems piecewise linear. All pieces get used.\n",
    "             # Weird thing is the gradients don't sum correctly...look into this more!\n",
    "             '1 Good 1 Bad', # bad feature barely used\n",
    "             '1 Good 1 Noisy', ] # piecewise linear; on a few pieces both get used, \n",
    "#              '2 Good+Hard 1 Noisy'] # both used\n",
    "exp_models = [two_good_model2, one_good_one_bad_model, one_good_one_noisy_model,]\n",
    "# two_good_hard_one_noisy_model]\n",
    "for exp_name, model in zip(exp_names, exp_models):\n",
    "    print(\"EXPERIMENT:\", exp_name)\n",
    "    y = torch.randn((20, 1))\n",
    "    x = torch.randn((20, 2))\n",
    "    x.requires_grad = True\n",
    "    pred = model(x)\n",
    "    err = pred - y\n",
    "    err.sum().backward()\n",
    "    print(np.round(x.grad.cpu().numpy(), 3))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT: 2 Good+Hard 1 Noisy\n",
      "x shape torch.Size([20, 3])\n",
      "[[-0.03  1.01  1.02]\n",
      " [ 0.    1.    1.  ]\n",
      " [ 0.    1.    1.  ]\n",
      " [ 0.    1.    1.  ]\n",
      " [-0.03  1.01  1.01]\n",
      " [ 0.    1.    1.  ]\n",
      " [-0.03  1.01  1.01]\n",
      " [ 0.    1.    1.  ]\n",
      " [ 0.    1.    1.  ]\n",
      " [-0.03  1.01  1.01]\n",
      " [ 0.    1.    1.  ]\n",
      " [ 0.    1.    1.  ]\n",
      " [-0.03  1.01  1.01]\n",
      " [-0.06  1.06  1.06]\n",
      " [ 0.    1.    1.  ]\n",
      " [-0.03  1.01  1.01]\n",
      " [-0.03  1.01  1.01]\n",
      " [ 0.04  0.94  0.95]\n",
      " [ 0.    1.    1.  ]\n",
      " [-0.03  1.01  1.01]]\n"
     ]
    }
   ],
   "source": [
    "exp_names = ['2 Good+Hard 1 Noisy'] # Hard-to-learn but better features are learned!\n",
    "exp_models = [two_good_hard_one_noisy_model] # [noisy, random, y - random]\n",
    "for exp_name, model in zip(exp_names, exp_models):\n",
    "    print(\"EXPERIMENT:\", exp_name)\n",
    "    y = torch.randn((20, 1))\n",
    "#     x = torch.randn((20, 3))\n",
    "    x1 = y + torch.randn(20, 1) / 5\n",
    "    x2 = torch.randn(20, 1)\n",
    "    x3 = y - x2\n",
    "    x = torch.cat([x1, x2, x3], dim=1)\n",
    "    print(\"x shape\", x.shape)\n",
    "    x.requires_grad = True\n",
    "    pred = model(x)\n",
    "    err = pred - y\n",
    "    err.sum().backward()\n",
    "    print(np.round(x.grad.cpu().numpy(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT: 2 Good+Hard10, 1 Noisy\n",
      "[[0.04 0.97 0.98 0.99 0.98 0.98 0.98 0.98 0.99 0.98 0.99 0.98]\n",
      " [0.04 0.97 0.98 0.99 0.98 0.98 0.98 0.98 0.99 0.98 0.99 0.98]\n",
      " [0.04 0.97 0.98 0.99 0.98 0.98 0.98 0.98 0.99 0.98 0.99 0.98]\n",
      " [0.04 0.97 0.98 0.99 0.98 0.98 0.98 0.98 0.99 0.98 0.99 0.98]\n",
      " [0.04 0.97 0.98 0.99 0.98 0.98 0.98 0.98 0.99 0.98 0.99 0.98]\n",
      " [0.03 0.98 0.98 0.98 0.98 0.98 0.99 0.99 0.98 0.99 0.98 0.99]\n",
      " [0.03 0.98 0.98 0.98 0.98 0.98 0.99 0.99 0.98 0.99 0.98 0.99]\n",
      " [0.04 0.97 0.98 0.99 0.98 0.98 0.98 0.98 0.99 0.98 0.99 0.98]\n",
      " [0.03 0.98 0.98 0.98 0.98 0.98 0.99 0.99 0.98 0.99 0.98 0.99]\n",
      " [0.03 0.98 0.98 0.98 0.98 0.98 0.99 0.99 0.98 0.99 0.98 0.99]\n",
      " [0.03 0.98 0.98 0.98 0.98 0.98 0.99 0.99 0.98 0.99 0.98 0.99]\n",
      " [0.03 0.98 0.98 0.98 0.98 0.98 0.99 0.99 0.98 0.99 0.98 0.99]\n",
      " [0.03 0.98 0.98 0.98 0.98 0.98 0.99 0.99 0.98 0.99 0.98 0.99]\n",
      " [0.03 0.98 0.98 0.98 0.98 0.98 0.99 0.99 0.98 0.99 0.98 0.99]\n",
      " [0.03 0.98 0.98 0.98 0.98 0.98 0.99 0.99 0.98 0.99 0.98 0.99]\n",
      " [0.46 1.14 1.15 1.18 1.14 1.14 1.15 1.18 1.16 1.18 1.16 1.17]\n",
      " [0.04 0.97 0.98 0.99 0.98 0.98 0.98 0.98 0.99 0.98 0.99 0.98]\n",
      " [0.03 0.98 0.98 0.98 0.98 0.98 0.99 0.99 0.98 0.99 0.98 0.99]\n",
      " [0.04 0.97 0.98 0.99 0.98 0.98 0.98 0.98 0.99 0.98 0.99 0.98]\n",
      " [0.03 0.98 0.98 0.98 0.98 0.98 0.99 0.99 0.98 0.99 0.98 0.99]]\n"
     ]
    }
   ],
   "source": [
    "exp_names = ['2 Good+Hard10, 1 Noisy'] # Hard-to-learn but better features are learned!\n",
    "exp_models = [one_noisy_hard10_good_welltrained] # [noisy, random, y - random]\n",
    "for exp_name, model in zip(exp_names, exp_models):\n",
    "    print(\"EXPERIMENT:\", exp_name)\n",
    "    y = torch.randn((20, 1))\n",
    "#     x = torch.randn((20, 3))\n",
    "    x1 = y + torch.randn(20, 1) / 5\n",
    "    x2 = torch.randn(20, 10)\n",
    "    x3 = y - x2.sum(dim=1, keepdims=True)\n",
    "    x = torch.cat([x1, x2, x3], dim=1)\n",
    "    x.requires_grad = True\n",
    "    pred = model(x)\n",
    "    err = pred - y\n",
    "    err.sum().backward()\n",
    "    print(np.round(x.grad.cpu().numpy(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT: 1 Good 1 error\n",
      "[[ 1.05  0.05]\n",
      " [ 0.92 -0.03]\n",
      " [ 0.97 -0.07]\n",
      " [ 0.92 -0.03]\n",
      " [ 0.95 -0.06]\n",
      " [ 1.05  0.05]\n",
      " [ 0.69  0.13]\n",
      " [ 1.14  0.14]\n",
      " [ 0.92 -0.03]\n",
      " [ 0.95 -0.06]\n",
      " [ 1.05  0.05]\n",
      " [ 0.95 -0.06]\n",
      " [ 0.92 -0.03]\n",
      " [ 1.05  0.05]\n",
      " [ 0.95 -0.06]\n",
      " [ 1.2  -0.23]\n",
      " [ 0.85 -0.15]\n",
      " [ 1.05  0.05]\n",
      " [ 1.05  0.05]\n",
      " [ 0.69  0.13]]\n"
     ]
    }
   ],
   "source": [
    "exp_names = ['1 Good 1 error'] # correct feature gets learned\n",
    "exp_models = [one_good_one_error_model]\n",
    "for exp_name, model in zip(exp_names, exp_models):\n",
    "    print(\"EXPERIMENT:\", exp_name)\n",
    "    y = torch.randn((20, 1))\n",
    "    x = torch.randn((20, 2))\n",
    "    \n",
    "#     x = torch.randn((20, 3))\n",
    "#     x1 = y + torch.randn(20, 1) / 5\n",
    "#     x2 = torch.randn(20, 1)\n",
    "#     x3 = y - x2\n",
    "#     x = torch.cat([x1, x2, x3], dim=1)\n",
    "#     print(\"x shape\", x.shape)\n",
    "    x.requires_grad = True\n",
    "    pred = model(x)\n",
    "    err = pred - y\n",
    "    err.sum().backward()\n",
    "    print(np.round(x.grad.cpu().numpy(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT: DoubleFeatureDoubleMistake\n",
      "[[ 0.97  0.  ]\n",
      " [ 1.06 -0.  ]\n",
      " [ 1.06 -0.  ]\n",
      " [ 1.06 -0.  ]\n",
      " [ 0.97  0.  ]\n",
      " [ 0.85 -0.15]\n",
      " [ 0.97  0.  ]\n",
      " [ 0.85 -0.15]\n",
      " [ 0.85 -0.15]\n",
      " [ 0.94 -0.03]\n",
      " [ 0.94 -0.03]\n",
      " [ 0.82 -0.18]\n",
      " [ 0.82 -0.18]\n",
      " [ 0.97  0.  ]\n",
      " [ 0.85 -0.15]\n",
      " [ 0.94 -0.03]\n",
      " [ 1.06 -0.  ]\n",
      " [ 0.85 -0.15]\n",
      " [ 0.97  0.  ]\n",
      " [ 0.82 -0.18]]\n",
      "EXPERIMENT: DoubleFeatureDoubleMistake2\n",
      "[[ 1.01  0.  ]\n",
      " [ 1.05  0.02]\n",
      " [ 1.   -0.01]\n",
      " [ 1.06  0.03]\n",
      " [ 1.06  0.03]\n",
      " [ 1.05  0.02]\n",
      " [ 1.02  0.  ]\n",
      " [ 1.01  0.  ]\n",
      " [ 1.01  0.  ]\n",
      " [ 1.   -0.01]\n",
      " [ 1.01  0.  ]\n",
      " [ 1.01  0.  ]\n",
      " [ 1.06  0.03]\n",
      " [ 1.   -0.01]\n",
      " [ 1.02  0.  ]\n",
      " [ 0.56 -0.17]\n",
      " [ 1.06  0.03]\n",
      " [ 1.   -0.01]\n",
      " [ 1.06  0.03]\n",
      " [ 1.01  0.  ]]\n"
     ]
    }
   ],
   "source": [
    "exp_names = ['DoubleFeatureDoubleMistake', 'DoubleFeatureDoubleMistake2']\n",
    "exp_models = [double_feature_double_mistake, double_feature_double_mistake2]\n",
    "for exp_name, model in zip(exp_names, exp_models):\n",
    "    print(\"EXPERIMENT:\", exp_name)\n",
    "    y = torch.randn((20, 1))\n",
    "    x = torch.randn((20, 2))\n",
    "\n",
    "    x.requires_grad = True\n",
    "    pred = model(x)\n",
    "    err = pred - y\n",
    "    err.sum().backward()\n",
    "    print(np.round(x.grad.cpu().numpy(), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
