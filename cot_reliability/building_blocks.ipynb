{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "import dataset\n",
    "import transformers\n",
    "import trl\n",
    "import tqdm\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from collections import deque\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from itertools import product\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 things\n",
    "# Spend 15 mins on things = 3.5 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging and pretty-printing\n",
    "\n",
    "TODO:\n",
    "- print in color\n",
    "- link to instrs for VSCode debugger\n",
    "- how to debug in JNotebook\n",
    "- memory stuff (debugging, printing)\n",
    "- printing stack trace in error message\n",
    "- timing\n",
    "- color in JNotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printc(text, color):\n",
    "    \"\"\"\n",
    "    Prints the given text in the specified color.\n",
    "\n",
    "    :param text: The text to be printed\n",
    "    :param color: The color in which the text is to be printed. \n",
    "                  Accepts 'red', 'green', 'yellow', 'blue', 'magenta', 'cyan', 'white'.\n",
    "    \"\"\"\n",
    "    colors = {\n",
    "        \"red\": \"\\033[91m\",\n",
    "        \"green\": \"\\033[92m\",\n",
    "        \"yellow\": \"\\033[93m\",\n",
    "        \"blue\": \"\\033[94m\",\n",
    "        \"magenta\": \"\\033[95m\",\n",
    "        \"cyan\": \"\\033[96m\",\n",
    "        \"white\": \"\\033[97m\",\n",
    "    }\n",
    "\n",
    "    # Check if the specified color is valid\n",
    "    if color not in colors:\n",
    "        print(\"Invalid color. Choose from 'red', 'green', 'yellow', 'blue', 'magenta', 'cyan', 'white'.\")\n",
    "        return\n",
    "\n",
    "    # Print the text in the specified color\n",
    "    print(f\"{colors[color]}{text}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy stuff\n",
    "\n",
    "TODO:\n",
    "- remind myself what broadcasts\n",
    "- fancy indexing\n",
    "- select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas stuff\n",
    "\n",
    "TODO:\n",
    "- Printing dataset stats\n",
    "- deduplicating\n",
    "- merging\n",
    "- groupby\n",
    "- pivot\n",
    "- loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization\n",
    "\n",
    "# TODO:\n",
    "- DIFFERENT SETTING\n",
    "  - imgs\n",
    "  - diff\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "vals = df['vals']\n",
    "# Pandas can compute all the standard stats at once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data stuff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_data(x, y):\n",
    "    \"\"\"\n",
    "    Analyzes the given data and prints the following:\n",
    "    - The shape of the data\n",
    "    - The number of unique values in the data\n",
    "    - The mean of the data\n",
    "    - The standard deviation of the data\n",
    "    - The minimum value in the data\n",
    "    - The maximum value in the data\n",
    "\n",
    "    :param x: The input data\n",
    "    :param y: The output data\n",
    "    \"\"\"\n",
    "    print(f\"Shape of x: {x.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n",
    "    print(f\"Number of unique values in x: {len(np.unique(x))}\")\n",
    "    print(f\"Number of unique values in y: {len(np.unique(y))}\")\n",
    "    print(f\"Mean of x: {np.mean(x)}\")\n",
    "    print(f\"Mean of y: {np.mean(y)}\")\n",
    "    print(f\"Standard deviation of x: {np.std(x)}\")\n",
    "    print(f\"Standard deviation of y: {np.std(y)}\")\n",
    "    print(f\"Minimum value in x: {np.min(x)}\")\n",
    "    print(f\"Minimum value in y: {np.min(y)}\")\n",
    "    print(f\"Maximum value in x: {np.max(x)}\")\n",
    "    print(f\"Maximum value in y: {np.max(y)}\")\n",
    "    print(f\"number of NaNs in x: {np.sum(np.isnan(x))}\")\n",
    "    print(f\"number of NaNs in y: {np.sum(np.isnan(y))}\")\n",
    "    print(f\"number of infs in x: {np.sum(np.isinf(x))}\")\n",
    "    print(f\"number of infs in y: {np.sum(np.isinf(y))}\")\n",
    "    \n",
    "    # Print dtypes\n",
    "    # Check duplicates\n",
    "    # check dataset balance\n",
    "    # check linear regression acc\n",
    "    \n",
    "    # For images, print representative samples\n",
    "    # For text, print representative samples\n",
    "    # For text, print lengths\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch stuff\n",
    "\n",
    "TODO:\n",
    "- Training loop\n",
    "- contiguous, etc.\n",
    "- weirdness (e.g. max)\n",
    "- examples of common networks\n",
    "- gotchas\n",
    "- debugging (e.g. by printing param values)\n",
    "- common hyperparameters\n",
    "- LR schedule\n",
    "- common initializations\n",
    "- NLL??\n",
    "- gradient clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch training loop\n",
    "\n",
    "batch_size = 32\n",
    "lr = 1e-3  # For training from scratch; for finetuning, use 1e-4\n",
    "weight_decay = ... # TODO: figure this out!\n",
    "\n",
    "model = torch.Linear(3, 3)\n",
    "# Getting a pretrained model:\n",
    "# model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
    "# Transformer from scratch\n",
    "# model = nn.TransformerDecoderLayer(\n",
    "#     d_model, \n",
    "#     nhead, \n",
    "#     dim_feedforward=2048, \n",
    "#     dropout=0.1, \n",
    "#     activation=<function relu>, \n",
    "#     layer_norm_eps=1e-05, \n",
    "#     batch_first=False, \n",
    "#     norm_first=False, \n",
    "#     bias=True, \n",
    "#     device=None, \n",
    "#     dtype=None\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)  # Either use Adam or AdamW\n",
    "# adamw_optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "# This takes in logits, not probabilities\n",
    "# Shape of logits is [B, V, ...] where B is batch size and V is the number of classes (NOT B, S, V)\n",
    "# Targets is [B, ...] where B is batch size and contains int idxs\n",
    "loss_fn = nn.CrossEntropyLoss(\n",
    "    # ignore_index=-100,  # -100 by default; set this to handle padding\n",
    "    # reduction='mean',  # 'mean' by default; set this to 'none' if you want to get the individual losses; all the loss fns have this option\n",
    "    # label_smoothing=0,  # I never use this, but apparently it's still a thing\n",
    ") \n",
    "# loss_fn = nn.MSELoss()  # For regression tasks\n",
    "# loss_fn = nn.BCEWithLogitsLoss()  # For binary classification tasks; takes in logits. If you have probs, use nn.BCELoss\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "\n",
    "# Cuda stuff\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Dummy dataset\n",
    "inputs = torch.rand(100, 3)\n",
    "targets = torch.randint(0, 3, (100,))\n",
    "train_dataset = torch.utils.data.TensorDataset(inputs, targets)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = torch.utils.data.TensorDataset(inputs, targets)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "def eval()\n",
    "\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, val_dataloader=None, epochs=10):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # Expects a dataloader\n",
    "    for i, X in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, X)  # Change X to y if you have labels\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            loss, current = loss.item(), i * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRL stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics/plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Git"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
